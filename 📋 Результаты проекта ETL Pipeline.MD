# Проект ETL Pipeline с использованием Airflow, MongoDB, PostgreSQL и ClickHouse

### Итоги реализации кода Docker Compose для ETL Pipeline

В данном коде была разработана конфигурация Docker Compose, которая создает и управляет несколькими сервисами, необходимыми для реализации ETL пайплайна. 

### Реализовано:

1. MongoDB:
   - Запущен контейнер с MongoDB, настроенный с учетными данными администратора.
   - Данные хранятся в постоянном хранилище, чтобы сохранить их между перезапусками контейнера.

2. Mongo Express:
   - Установлен и запущен Mongo Express для удобного веб-интерфейса работы с MongoDB.
   - Конфигурация позволяет подключаться к MongoDB с заданными учетными данными.

3. ClickHouse:
   - Развернут контейнер ClickHouse для хранения и обработки аналитических данных.
   - Настроены учетные данные администратора и постоянное хранилище для данных и конфигураций.

4. PostgreSQL:
   - Запущен контейнер PostgreSQL с настройкой учетных данных для Airflow.
   - Включен контроль состояния контейнера с помощью healthcheck, чтобы убедиться, что база данных готова к использованию.

5. Airflow Webserver:
   - Настроен веб-сервер Airflow для управления задачами ETL.
   - Используется Dockerfile для сборки образа, а также определены переменные среды для подключения к PostgreSQL и настройки безопасности.

6. Airflow Scheduler:
   - Развернут планировщик Airflow для выполнения DAG (Directed Acyclic Graph) задач.
   - Обеспечивает выполнение задач в соответствии с установленным расписанием.

7. Grafana:
   - Установлен контейнер Grafana для визуализации данных и мониторинга показателей.
   - Настроены учетные данные администратора для доступа к интерфейсу.

8. Сеть и тома:
   - Создана общая сеть для взаимодействия всех контейнеров.
   - Определены постоянные тома для хранения данных, чтобы обеспечить их сохранность.
